"""
Tool Calling ë©”ì»¤ë‹ˆì¦˜ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” LLMì´ ì–´ë–»ê²Œ ë„êµ¬ í˜¸ì¶œ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ”ì§€ ëª…í™•íˆ ë³´ì—¬ì¤ë‹ˆë‹¤.
"""

import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from src.components.search_tool import get_search_tools

load_dotenv()


def test_tool_calling_decision():
    """LLMì˜ ë„êµ¬ í˜¸ì¶œ íŒë‹¨ ê³¼ì •ì„ í…ŒìŠ¤íŠ¸"""

    # LLM ì„¤ì •
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    search_tools = get_search_tools()
    llm_with_tools = llm.bind_tools(search_tools)

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    system_prompt = """
You are a helpful AI assistant.

Use the tavily_search tool in the following situations:
1. When real-time news or current information is needed
2. When specific information about companies, people, or events is required
3. When variable information like weather, stocks, or exchange rates is needed
4. When the user explicitly requests a search

For general questions, respond directly without using tools.
"""

    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
    test_cases = [
        "ì•ˆë…•í•˜ì„¸ìš”!",                    # ì¼ë°˜ ëŒ€í™” â†’ ë„êµ¬ í˜¸ì¶œ ì•ˆí•¨
        "íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ë€ ë¬´ì—‡ì¸ê°€ìš”?",      # ì¼ë°˜ ì§€ì‹ â†’ ë„êµ¬ í˜¸ì¶œ ì•ˆí•¨
        "ì‚¼ì„±ì „ì ì£¼ê°€ ì•Œë ¤ì¤˜",           # ì‹¤ì‹œê°„ ì •ë³´ â†’ ë„êµ¬ í˜¸ì¶œ
        "ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?",           # ì‹¤ì‹œê°„ ì •ë³´ â†’ ë„êµ¬ í˜¸ì¶œ
        "ìµœê·¼ AI ë‰´ìŠ¤ ê²€ìƒ‰í•´ì¤˜",          # ëª…ì‹œì  ê²€ìƒ‰ ìš”ì²­ â†’ ë„êµ¬ í˜¸ì¶œ
    ]

    print("ğŸ” Tool Calling íŒë‹¨ í…ŒìŠ¤íŠ¸\n" + "="*50)

    for i, question in enumerate(test_cases, 1):
        print(f"\n{i}. ì§ˆë¬¸: '{question}'")

        # LLMì— ì§ˆë¬¸
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=question)
        ]

        response = llm_with_tools.invoke(messages)

        # ì‘ë‹µ ë¶„ì„ - AIMessage íƒ€ì… ì²´í¬ ì¶”ê°€
        if (
            isinstance(response, AIMessage)
            and hasattr(response, 'tool_calls')
            and response.tool_calls
        ):
            print(f"   ğŸ“ ë„êµ¬ í˜¸ì¶œ: YES")
            print(f"   ğŸ”§ ë„êµ¬: {response.tool_calls[0]['name']}")
            print(f"   ğŸ“ ê²€ìƒ‰ì–´: {response.tool_calls[0]['args']['query']}")
            print(f"   ğŸ¯ íŒë‹¨: SEARCH ë…¸ë“œë¡œ ì´ë™")
        else:
            print(f"   ğŸ“ ë„êµ¬ í˜¸ì¶œ: NO")
            print(f"   ğŸ’¬ ì¼ë°˜ ì‘ë‹µ: {response.content[:100]}...")
            print(f"   ğŸ¯ íŒë‹¨: ë°”ë¡œ ì‘ë‹µ ì™„ë£Œ")


def show_actual_response_structure():
    """ì‹¤ì œ LLM ì‘ë‹µ êµ¬ì¡°ë¥¼ ë³´ì—¬ì¤Œ"""

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    search_tools = get_search_tools()
    llm_with_tools = llm.bind_tools(search_tools)

    print("\n" + "="*50)
    print("ğŸ—ï¸ ì‹¤ì œ LLM ì‘ë‹µ êµ¬ì¡°")
    print("="*50)

    # ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸
    messages = [
        SystemMessage(
            content="Use tavily_search tool when real-time information is needed."),
        HumanMessage(content="ì‚¼ì„±ì „ì ì£¼ê°€ ì•Œë ¤ì¤˜")
    ]

    response = llm_with_tools.invoke(messages)

    print(f"\nğŸ“‹ ì‘ë‹µ íƒ€ì…: {type(response)}")
    print(f"ğŸ“‹ ì‘ë‹µ í´ë˜ìŠ¤: {response.__class__.__name__}")
    print(f"ğŸ“‹ ì½˜í…ì¸ : '{response.content}'")

    # AIMessage íƒ€ì… ì²´í¬ í›„ tool_calls í™•ì¸
    has_tool_calls = (
        isinstance(response, AIMessage)
        and hasattr(response, 'tool_calls')
        and response.tool_calls
    )
    print(f"ğŸ“‹ ë„êµ¬ í˜¸ì¶œ ìˆìŒ: {has_tool_calls}")

    if has_tool_calls and isinstance(response, AIMessage):
        print(f"\nğŸ”§ Tool Calls êµ¬ì¡°:")
        for i, tool_call in enumerate(response.tool_calls):
            print(f"   [{i}] ID: {tool_call['id']}")
            print(f"   [{i}] ì´ë¦„: {tool_call['name']}")
            print(f"   [{i}] ì¸ìˆ˜: {tool_call['args']}")

    print(f"\nğŸ¯ ê²°ë¡ : ì´ ì‘ë‹µì€ {'ë„êµ¬ í˜¸ì¶œ' if has_tool_calls else 'ì¼ë°˜ í…ìŠ¤íŠ¸'}ì…ë‹ˆë‹¤!")


if __name__ == "__main__":
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        exit(1)

    test_tool_calling_decision()
    show_actual_response_structure()
